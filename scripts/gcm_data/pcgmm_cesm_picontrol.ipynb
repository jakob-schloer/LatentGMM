{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM in PCA space of ensemble of reanalysis datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy as ctp\n",
    "import seaborn as sns\n",
    "from sklearn import mixture, decomposition\n",
    "\n",
    "from latgmm.utils import utenso, preproc, eof, utdata, utstats, metric\n",
    "import latgmm.geoplot as gpl\n",
    "\n",
    "plt.style.use(\"../../paper.mplstyle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"../../data/cmip6/piControl/CESM2/ssta_lat-31_32_lon130_-70_gr1.0_norm-zscore.nc\"\n",
    "normalization = 'zscore'\n",
    "\n",
    "ds = xr.open_dataset(datafile)\n",
    "\n",
    "# Normalization\n",
    "if normalization is not None:\n",
    "    attributes = {}\n",
    "    ds_norm = []\n",
    "    for var in list(ds.data_vars):\n",
    "        scaler = preproc.Normalizer(method=normalization)\n",
    "        buff = scaler.fit_transform(ds[var])\n",
    "        buff.attrs = {'normalizer': scaler}\n",
    "        ds_norm.append(buff)\n",
    "\n",
    "    ds = xr.merge(ds_norm) \n",
    "\n",
    "ds = ds.assign_coords(member=('time', ['piControl']*len(ds.time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pcs_from_reanalysis = False\n",
    "if use_pcs_from_reanalysis:\n",
    "    datafile = \"../data/reanalysis/monthly/ssta_merged_dataset.nc\"\n",
    "    normalization = 'zscore'\n",
    "    ds4eof = xr.open_dataset(datafile)\n",
    "    # Get land sea mask from model\n",
    "    mask1 = ds['ssta'].isel(time=0).isnull()\n",
    "    mask2 = ds4eof['ssta'].isel(time=0).isnull()\n",
    "    merged_mask = np.logical_or(mask1, mask2)\n",
    "\n",
    "    ds = ds.where(~merged_mask, other=np.nan)\n",
    "    ds4eof = ds4eof.where(~merged_mask, other=np.nan)\n",
    "\n",
    "    # Normalization\n",
    "    if normalization is not None:\n",
    "        attributes = {}\n",
    "        ds_norm = []\n",
    "        for var in list(ds4eof.data_vars):\n",
    "            scaler = preproc.Normalizer(method=normalization)\n",
    "            buff = scaler.fit_transform(ds4eof[var])\n",
    "            buff.attrs = {'normalizer': scaler}\n",
    "            ds_norm.append(buff)\n",
    "\n",
    "        ds4eof = xr.merge(ds_norm) \n",
    "else:\n",
    "    ds4eof = ds\n",
    "\n",
    "n_components = 2\n",
    "sppca = eof.SpatioTemporalPCA(ds4eof, n_components=n_components)\n",
    "print(f\"Explained variance: {np.sum(sppca.explained_variance())}\")\n",
    "eofs = sppca.get_eofs()\n",
    "z = sppca.transform(ds)\n",
    "pcs = xr.DataArray(z, dims=['time', 'component'], coords={'time': ds['time'], 'component': np.arange(n_components)})\n",
    "pcs = pcs.assign_coords(member=('time', ds['member'].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot EOF maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOF maps\n",
    "vars = list(ds.data_vars)\n",
    "fig = plt.figure(figsize=(7, 2*len(vars)))\n",
    "proj = ctp.crs.PlateCarree(central_longitude=180)\n",
    "axs = []\n",
    "for i in range(sppca.n_components):\n",
    "    comp = eofs.isel(eof=i)\n",
    "    for j, var in enumerate(vars):\n",
    "        ax = fig.add_subplot(len(vars), sppca.n_components, i+sppca.n_components*j+1, projection=proj)\n",
    "        im = gpl.plot_map(comp[var], central_longitude=180, ax=ax,\n",
    "                     bar='continuous', vmin=-.03, vmax=.03, add_bar=False)\n",
    "        im['gl'].top_labels = False \n",
    "        if i > 0:\n",
    "            im['gl'].left_labels = False \n",
    "        axs.append(ax)\n",
    "        \n",
    "cbar_ax = fig.add_axes([0.99, .2, 0.01, 0.6])\n",
    "cb = fig.colorbar(im['im'], cax=cbar_ax, orientation='vertical', shrink=0.6, extend='both')\n",
    "cb.set_label(label=rf\"EOF\")\n",
    "\n",
    "gpl.enumerate_subplots(axs, pos_x=.01, pos_y=.85)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ENSO events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utenso)\n",
    "month_range=[12, 2]\n",
    "x_enso, x_events = utenso.select_enso_events(ds, month_range=month_range, threshold=0.5)\n",
    "z_enso = xr.DataArray(\n",
    "    data=sppca.transform(x_enso),\n",
    "    coords={'time': x_enso['time'].data, 'eof': np.arange(1, sppca.n_components+1)}\n",
    ").assign_coords(member=('time', x_enso['member'].data))\n",
    "z_events = xr.DataArray(\n",
    "    data=sppca.transform(x_events),\n",
    "    coords={'time': x_events['time'].data, 'eof': np.arange(1, sppca.n_components+1)}\n",
    ").assign_coords(member=('time', x_events['member'].data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot latent encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(z_enso.isel(eof=0), z_enso.isel(eof=1), '.', color='k')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check differences between datasets\n",
    "plparam = { \n",
    "    'COBE2':    dict(linestyle='', marker='o', markersize=4),\n",
    "    'ErSSTv5':     dict(linestyle='', marker='v', markersize=4),\n",
    "    'HadISST':  dict(linestyle='', marker='^', markersize=4), \n",
    "    'ORAS5':    dict(linestyle='', marker='s', markersize=4), \n",
    "    'GODAS':  dict(linestyle='', marker='+', markersize=4),\n",
    "    'SODA':    dict(linestyle='', marker='x', markersize=4), \n",
    "    'ERA5':     dict(linestyle='', marker='D', markersize=4), \n",
    "    'CERA-20c':     dict(linestyle='', marker='*', markersize=4), \n",
    "    'piControl':     dict(linestyle='', marker='o', markersize=4), \n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "unique_members = np.unique(x_events['member'].data)\n",
    "for i, membername in enumerate(unique_members):\n",
    "    idx = np.where(x_events['member'].data == membername)[0]\n",
    "    ax.plot(z_events.isel(eof=0)[idx], z_events.isel(eof=1)[idx], label=membername,\n",
    "            **plparam[membername])\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan number of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = np.arange(1, 10, 1)\n",
    "n_runs = 50\n",
    "result = []\n",
    "for k in n_classes:\n",
    "    for r in range(n_runs):\n",
    "        gmm = mixture.GaussianMixture(n_components=k, \n",
    "                                      covariance_type='full', max_iter=100)\n",
    "        gmm.fit(z_enso.data)\n",
    "        result.append(\n",
    "            {'k': k, 'bic': gmm.bic(z_enso.data), 'gmm': gmm}\n",
    "        )\n",
    "result = pd.DataFrame(result)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax = sns.boxplot(data=result, x='k', y='bic', ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GMM\n",
    "reload(gpl)\n",
    "n_cluster=5\n",
    "n_rand = 42 \n",
    "gmm_pca = mixture.GaussianMixture(n_components=n_cluster, \n",
    "                      covariance_type='full', max_iter=100,\n",
    "                      random_state=n_rand)\n",
    "gmm_pca.fit(z_enso.data)\n",
    "\n",
    "# Plotting\n",
    "plparam = { \n",
    "    'COBE2':    dict(linestyle='', marker='o', markersize=3),\n",
    "    'ErSSTv5':  dict(linestyle='', marker='v', markersize=3),\n",
    "    'HadISST':  dict(linestyle='', marker='^', markersize=3), \n",
    "    'ORAS5':    dict(linestyle='', marker='s', markersize=3), \n",
    "    'GODAS':    dict(linestyle='', marker='+', markersize=3),\n",
    "    'SODA':     dict(linestyle='', marker='x', markersize=3), \n",
    "    'ERA5':     dict(linestyle='', marker='d', markersize=3), \n",
    "    'CERA-20c': dict(linestyle='', marker='*', markersize=3), \n",
    "    'piControl': dict(linestyle='', marker='.', markersize=3), \n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Plot gmm means\n",
    "gmm_order = np.arange(gmm_pca.means_.shape[0]) \n",
    "gmm_order = np.array([1, 3, 5, 4, 2]) -1 # all sst \n",
    "gmclrs = ['maroon', 'darkorange', 'gold', 'lightblue', 'darkblue', 'black']\n",
    "for i, k in enumerate(gmm_order):\n",
    "    mean = gmm_pca.means_[k, :]\n",
    "    if gmm_pca.covariance_type == \"full\":\n",
    "        Sigma = gmm_pca.covariances_[k, :]\n",
    "    elif gmm_pca.covariance_type == \"diag\":\n",
    "        Sigma = np.diag(gmm_pca.covariances_[k, :])\n",
    "\n",
    "    gmkwargs= dict(fill=False)\n",
    "    if gmclrs is not None:\n",
    "        gmkwargs['edgecolor'] = 'k' #gmclrs[i] \n",
    "        gmkwargs['facecolor'] = gmclrs[i] \n",
    "        gmkwargs['fill'] = True\n",
    "        gmkwargs['alpha'] = 0.5\n",
    "\n",
    "    for p in [0.9, 0.5, 0.1]:\n",
    "        if p==0.1:\n",
    "            gmkwargs['label'] = f\"c={k+1}\"\n",
    "        gpl.plot_2dgaussian(mean, Sigma,\n",
    "                             ax=ax, p=p, **gmkwargs)\n",
    "\n",
    "ax.set_xlabel(\"EOF 1\")\n",
    "ax.set_ylabel(\"EOF 2\")\n",
    "\n",
    "for i, member in enumerate(np.unique(ds['member'].data)):\n",
    "    idx = np.where(x_events['member'].data == member)[0]\n",
    "    ax.plot(z_events.isel(eof=0)[idx], z_events.isel(eof=1)[idx], color='k', label=member,\n",
    "            **plparam[member])\n",
    "\n",
    "ax.legend(bbox_to_anchor=(0., 1.0, 1., 0.1), loc=\"lower left\", ncol=3, mode='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean of Gaussian mixtures\n",
    "plparam = {'ssta': dict(vmin=-1.5, vmax=1.5, step=0.25, cmap='RdBu_r', centercolor=\"#ffffff\"),\n",
    "           'ssha': dict(vmin=-.15, vmax=.15, step=0.025,cmap='RdGy_r', centercolor=\"#ffffff\")}\n",
    "labels = ['Extreme El Nino', 'EP El Nino', 'CP El Nino', 'EP La Nina', 'CP La Nina',]\n",
    "\n",
    "means = sppca.inverse_transform(gmm_pca.means_, newdim='mu')\n",
    "# Unnormalize\n",
    "if 'normalizer' in ds['ssta'].attrs.keys():\n",
    "    for var in list(ds.data_vars):\n",
    "        means[var] = ds[var].attrs['normalizer'].inverse_transform(means[var])\n",
    "\n",
    "vars = ds.data_vars\n",
    "fig = plt.figure(figsize=(4*len(vars), 1.7*len(gmm_order)))\n",
    "proj = ctp.crs.PlateCarree(central_longitude=180)\n",
    "for i, k in enumerate(gmm_order):\n",
    "    mu = means.sel(mu=k)\n",
    "    for j, var in enumerate(vars):\n",
    "        idx = len(vars)*i+j+1\n",
    "        ax = fig.add_subplot(len(gmm_order), len(vars), idx, projection=proj)\n",
    "        im = gpl.plot_map(mu[var], central_longitude=180, ax=ax, \n",
    "                          bar='discrete', add_bar=False, **plparam[var])\n",
    "        im['gl'].top_labels = False \n",
    "        ax.set_title(rf\"$c_{k+1}$\", fontsize=14)\n",
    "#        ax.set_title(labels[i], fontsize=12)\n",
    "\n",
    "# Shared colorbar\n",
    "cbar_ax = fig.add_axes([0.2, -.01, 0.6, 0.01])\n",
    "cbar = plt.colorbar(im['im'], orientation='horizontal', shrink=0.7,\n",
    "                    cax=cbar_ax, extend='both')\n",
    "cbar.set_label(f\"SST anomalies\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save means\n",
    "if False:\n",
    "    means.attrs['gmm_sort'] = gmm_order\n",
    "    means.to_netcdf(\"../output/pcgmm/pcgmm_sst_means.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event weights\n",
    "p_c_given_x = utenso.posterior_weights(\n",
    "    z_events.data, means=gmm_pca.means_, covariances=gmm_pca.covariances_,\n",
    "    prior_weights=gmm_pca.weights_\n",
    ")\n",
    "# convert to xarray\n",
    "p_c_given_x_da = xr.DataArray(data=p_c_given_x, dims=['time', 'classes'], \n",
    "                              coords={ \n",
    "                                'time': z_events['time'].data,\n",
    "                                'member': ('time', z_events['member'].data),\n",
    "                                'classes': np.arange(p_c_given_x.shape[1]) + 1\n",
    "                              })\n",
    "\n",
    "# Mean posterior weights\n",
    "timepoints = np.unique(p_c_given_x_da['time'].data)\n",
    "p_c_given_x_mean = []\n",
    "p_c_given_x_std = []\n",
    "for t in timepoints:\n",
    "    weight = p_c_given_x_da.sel(time=t)\n",
    "    if len(weight.shape) > 1:\n",
    "        p_c_given_x_mean.append(weight.mean(dim='time').data)\n",
    "        p_c_given_x_std.append(weight.std(dim='time').data)\n",
    "    else:\n",
    "        p_c_given_x_mean.append(weight.data)\n",
    "        p_c_given_x_std.append(np.zeros(shape=n_cluster))\n",
    "\n",
    "years = np.array([t.year for t in timepoints], dtype=int)\n",
    "p_c_given_x_mean = xr.DataArray(data=p_c_given_x_mean, coords={'time': years, 'classes':p_c_given_x_da['classes']})        \n",
    "p_c_given_x_std = xr.DataArray(data=p_c_given_x_std, coords={'time': years, 'classes':p_c_given_x_da['classes']})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot posterior weights\n",
    "labels = ['Extreme El Nino', 'EP El Nino', 'CP El Nino', 'EP La Nina', 'CP La Nina',]\n",
    "n_samples, n_classes = p_c_given_x.shape\n",
    "fig, axs = plt.subplots(n_classes, 1, figsize=(7, 1.5*n_classes), sharex='col', sharey='row')\n",
    "\n",
    "for i, k in enumerate(gmm_order):\n",
    "    axs[i].bar(p_c_given_x_mean['time'].data, height=p_c_given_x_mean.sel(classes=k+1).data,\n",
    "               color=gmclrs[i], label=labels[i])\n",
    "    axs[i].grid(axis='x')\n",
    "    axs[i].set_ylabel(rf'$p(c_{k+1}|z)$')\n",
    "    axs[i].set_ylim([0,1])\n",
    "    axs[i].set_yticks([0, .5, 1])\n",
    "    axs[i].legend(bbox_to_anchor=(.72, 1.0, 0.3, 0.1), loc=\"lower right\", fontsize=10)\n",
    "\n",
    "gpl.enumerate_subplots(axs, pos_x=0.01, pos_y=1.1, fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std of weights between datasets\n",
    "labels = ['Extreme El Nino', 'EP El Nino', 'CP El Nino', 'EP La Nina', 'CP La Nina',]\n",
    "fig, axs = plt.subplots(n_classes, 1, figsize=(7, 1.1*n_classes), sharex='col', sharey='row')\n",
    "\n",
    "for i, k in enumerate(gmm_order):\n",
    "    axs[i].bar(p_c_given_x_std['time'].data, height=p_c_given_x_std.sel(classes=k+1),\n",
    "                 width=4e2, color=gmclrs[i], label=rf\"{labels[i]}\")\n",
    "    axs[i].grid(axis='x')\n",
    "    axs[i].set_ylabel(rf'$\\sigma ( p(c_{k+1}|z))$')\n",
    "    axs[i].set_ylim([0,1])\n",
    "    axs[i].set_yticks([0, .5, 1])\n",
    "    axs[i].legend(bbox_to_anchor=(.7, .5, 0.3, 0.1), loc=\"lower right\", fontsize=10)\n",
    "\n",
    "_ = gpl.enumerate_subplots(axs, pos_x=0.01, pos_y=.75, fontsize=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute monthly weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly weights\n",
    "p_c_given_x_month = utenso.posterior_weights(\n",
    "    z_enso.data, means=gmm_pca.means_, covariances=gmm_pca.covariances_,\n",
    "    prior_weights=gmm_pca.weights_\n",
    ")\n",
    "# convert to xarray\n",
    "p_c_given_x_month = xr.DataArray(data=p_c_given_x_month, dims=['time', 'classes'], \n",
    "                              coords={ \n",
    "                                'time': z_enso['time'].data,\n",
    "                                'member': ('time', z_enso['member'].data),\n",
    "                                'classes': np.arange(p_c_given_x_month.shape[1]) + 1\n",
    "                              })\n",
    "\n",
    "# Mean posterior weights\n",
    "timepoints = np.unique(p_c_given_x_month['time'].data)\n",
    "weight_month_mean = []\n",
    "weight_month_std = []\n",
    "for t in timepoints:\n",
    "    weight = p_c_given_x_month.sel(time=t)\n",
    "    if len(weight.shape) > 1:\n",
    "        weight_month_mean.append(weight.mean(dim='time').data)\n",
    "        weight_month_std.append(weight.std(dim='time').data)\n",
    "    else:\n",
    "        weight_month_mean.append(weight.data)\n",
    "        weight_month_std.append(np.zeros(shape=5))\n",
    "\n",
    "weight_month_mean = xr.DataArray(data=weight_month_mean, coords={'time':timepoints, 'classes':p_c_given_x_month['classes']})        \n",
    "weight_month_std = xr.DataArray(data=weight_month_std, coords={'time':timepoints, 'classes':p_c_given_x_month['classes']})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save probability weights\n",
    "if False:\n",
    "    p_c_given_x_mean.attrs['gmm_sort'] = gmm_order\n",
    "    p_c_given_x_mean.name = 'p_c_given_x'\n",
    "    p_c_given_x_mean.to_netcdf(\"../output/pcgmm/pcgmm_weights_events_mean_sst.nc\")\n",
    "if False:\n",
    "    weight_month_mean.attrs['gmm_sort'] = gmm_order\n",
    "    weight_month_mean.name = 'p_c_given_x'\n",
    "    weight_month_mean.to_netcdf(\"../output/pcgmm/pcgmm_weights_mon_mean_sst.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decadal variability of Nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_ssta = ds['ssta'].attrs['normalizer'].inverse_transform(ds['ssta'])\n",
    "nino_indices = utenso.get_nino_indices(da_ssta, antimeridian=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly weighting of Nino3.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weight_month_mean\n",
    "nino34 = nino_indices['nino34']\n",
    "# Make sure weights and nino-indices are on the same time points\n",
    "tmax = nino34['time'].max() if nino34['time'].max() < weights['time'].max() else weights['time'].max()\n",
    "tmin = nino34['time'].min() if nino34['time'].min() > weights['time'].min() else weights['time'].min()\n",
    "nino34 = nino34.sel(time=slice(tmin.data, tmax.data)).rolling(time=3, center=True).mean()\n",
    "weights = weights.sel(time=slice(tmin.data, tmax.data))\n",
    "weights['time'] = np.array(weights['time'].data)\n",
    "nino34['time'] = np.array(nino34['time'].data)\n",
    "\n",
    "nino34 = nino34.sel(time=weights['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, \n",
    "                        width_ratios=[3,1],\n",
    "                        figsize=(8, 2.5),\n",
    "                        sharey=True)\n",
    "#axs[0].bar(nino34['time'].data, height=nino34.data, width=4e2, label=rf'y', color='k')\n",
    "im, bins, _ = axs[1].hist(nino34.data, bins='auto', density=True, orientation='horizontal',\n",
    "                          histtype='bar', color='k', alpha=.5, label=rf'$y$')\n",
    "for i, k in enumerate(gmm_order):\n",
    "    n34_k = nino34 * weights.sel(classes=k+1)\n",
    "    idx_nonzero = np.where(weights.sel(classes=k+1).data > 0.55)[0]\n",
    "    n34_k = n34_k[idx_nonzero]\n",
    "    years = np.array([t.year for t in n34_k['time'].data], dtype=int)\n",
    "    axs[0].bar(years, height=n34_k.data, width=1,\n",
    "                   color=gmclrs[i])#, label=rf'$p(c={k}|z_t) \\cdot y$')\n",
    "    axs[1].hist(n34_k.data, bins=bins, density=True, orientation='horizontal',\n",
    "                histtype='step', color=gmclrs[i], linewidth=1.5, #alpha=.4,\n",
    "                label=rf'$p(c={k}|z_t) \\cdot y$')\n",
    "\n",
    "axs[0].set_ylabel(f'$p_i \\cdot y$')\n",
    "axs[0].set_ylabel(\"Nino3.4\")\n",
    "axs[1].set_xlabel(\"density\")\n",
    "#axs[1].legend(bbox_to_anchor=(1., .1, .6, 1.), loc=\"lower left\", ncol=1)\n",
    "fig.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.07, 1.15, .9, 0.1), mode='expand')\n",
    "gpl.enumerate_subplots(axs, pos_x=0.03, pos_y=.85, fontsize=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decadal variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_covariance(da: xr.DataArray, window_size: int):\n",
    "    covs = []\n",
    "    times = []\n",
    "    for i in range(window_size-1, len(da['time'])):\n",
    "        # Select window\n",
    "        chunk = da.isel(time=slice(i-window_size+1, i+1))\n",
    "        # Compute covariance\n",
    "        cov = np.cov(chunk.data)\n",
    "        covs.append(cov)\n",
    "        times.append(chunk.isel(time=int(window_size/2))['time'].data)\n",
    "    \n",
    "    return np.array(covs), np.stack(times)\n",
    "\n",
    "\n",
    "\n",
    "# Weighted Nino3.4\n",
    "nino34_k = []\n",
    "for k in weights['classes']:\n",
    "    nino34_k.append(nino34 * weights.sel(classes=k))\n",
    "nino34_k = xr.concat(nino34_k, dim=pd.Index(weights['classes'].data, name='classes'))\n",
    "\n",
    "# Rolling mean variance over n_years\n",
    "n_years = 30\n",
    "nino34_var, times = rolling_window_covariance(nino34, window_size=3*n_years)\n",
    "nino34_var = xr.DataArray(nino34_var, coords=dict(time=times))\n",
    "nino34_k_cov, times = rolling_window_covariance(nino34_k, window_size=3*n_years)\n",
    "nino34_k_cov = xr.DataArray(nino34_k_cov, coords=dict(time=times, c1=nino34_k['classes'].data, c2=nino34_k['classes'].data))\n",
    "\n",
    "# Sum of covariances\n",
    "n_times, n_features, _ = nino34_k_cov.shape\n",
    "sum_covariances = np.zeros(n_times)\n",
    "for i in range(n_features):\n",
    "    for j in range(i+1, n_features):\n",
    "        sum_covariances += nino34_k_cov.data[:, i, j]\n",
    "nino34_k_cov_sum = xr.DataArray(2*sum_covariances, coords=dict(time=nino34_k_cov['time'].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack plot every 10 years\n",
    "import cftime\n",
    "n_step = 10\n",
    "# Time points\n",
    "year_arr = np.arange(nino34_k_cov['time'].data.min().year, nino34_k_cov['time'].data.max().year + 2, n_step)\n",
    "time_arr = [cftime.DatetimeNoLeap(y, 1, 1) for y in year_arr]\n",
    "# Select time points and stack plots\n",
    "stacked_lines = [(nino34_k_cov.sel(time=time_arr, method='nearest').isel(c1=k, c2=k) / nino34_var\n",
    "                  ) for k in gmm_order]\n",
    "stacked_lines.append(\n",
    "    nino34_k_cov_sum.sel(time=time_arr, method='nearest') / nino34_var\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "class_names = ['Extreme El Nino', 'EP El Nino', 'CP El Nino', 'EP La Nina', 'CP La Nina',]\n",
    "clrs = gmclrs[:len(gmm_order)]\n",
    "clrs.append('lightgrey')\n",
    "labels = [rf\"k={k}\" for k in gmm_order]\n",
    "labels.append(\"cov\")\n",
    "nrows, ncols = (3, 2)\n",
    "fig = plt.figure(figsize=(9, nrows*2.))\n",
    "gs = gridspec.GridSpec(nrows, ncols, width_ratios=[3,1], height_ratios=[2,1,2])\n",
    "axs = [fig.add_subplot(gs[0,0]), fig.add_subplot(gs[0,1])]\n",
    "axs.append(fig.add_subplot(gs[1,0], sharex=axs[0]))\n",
    "axs.append(fig.add_subplot(gs[2,0], sharex=axs[0]))\n",
    "axs.append(fig.add_subplot(gs[1:,1]))\n",
    "\n",
    "# Nino34 time-series and hisplot\n",
    "im, bins, _ = axs[1].hist(nino34.data, bins='auto', density=True, orientation='horizontal',\n",
    "                          histtype='bar', color='k', alpha=.9, label=f'Nino3.4')\n",
    "for i, k in enumerate(gmm_order):\n",
    "    n34_k = nino34 * weights.sel(classes=k+1)\n",
    "    idx_nonzero = np.where(weights.sel(classes=k+1).data > 0.5)[0]\n",
    "    n34_k = n34_k[idx_nonzero]\n",
    "    years = np.array([t.year for t in n34_k['time'].data], dtype=int)\n",
    "    axs[0].bar(years, height=n34_k.data, width=1,\n",
    "                   color=gmclrs[i])#, label=rf'$p(c={k}|z_t) \\cdot y$')\n",
    "    axs[1].hist(n34_k.data, bins=bins, density=True, orientation='horizontal',\n",
    "                histtype='step', color=gmclrs[i], linewidth=1.5, #alpha=.4,\n",
    "                label=class_names[i])\n",
    "#                label=r'$p(c_{k}|z_t) \\cdot y$'.replace('k', str(k+1)))\n",
    "#axs[0].set_xlim(np.min(years), np.max(years))\n",
    "axs[0].set_ylabel(\"Nino3.4\")\n",
    "\n",
    "axs[1].set_xlabel(r\"density\")\n",
    "\n",
    "# Variance of Nino34\n",
    "years = np.arange(nino34_var['time'].data.min().year, nino34_var['time'].data.max().year + 2, n_step)\n",
    "time_arr = [cftime.DatetimeNoLeap(y, 1, 1) for y in years]\n",
    "variance = nino34_var.sel(time=time_arr, method='nearest')\n",
    "#axs[2].plot(nino34_var['time'], nino34_var, color='darkgreen',\n",
    "#           label=r'$\\sigma_{30y}$ (Nino3.4)')\n",
    "#axs[2].fill_between(nino34_var['time'], np.zeros(len(nino34_var['time'])), nino34_var, color='darkgreen', alpha=.5)\n",
    "axs[2].bar(years, height=variance, width=10, color='darkgreen', edgecolor='darkgreen', alpha=.5, \n",
    "           label=r'$\\sigma$(Nino3.4)')\n",
    "axs[2].set_ylabel(r\"variance\")\n",
    "\n",
    "# Decadel variability\n",
    "bottom = np.zeros_like(stacked_lines[0])\n",
    "for i, stack in enumerate(stacked_lines):\n",
    "    axs[3].bar(years, stack, bottom=bottom, width=10, color=clrs[i], label=labels[i])\n",
    "    bottom += stack\n",
    "axs[3].set_ylabel(r\"norm. variance\")\n",
    "\n",
    "# Legend in seperate subplot\n",
    "hands, labs = axs[1].get_legend_handles_labels()\n",
    "hand2, lab2 = axs[2].get_legend_handles_labels()\n",
    "hand3, lab3 = axs[3].get_legend_handles_labels()\n",
    "hands.append(hand2[-1])\n",
    "hands.append(hand3[-1])\n",
    "labs.append(lab2[-1])\n",
    "labs.append(lab3[-1])\n",
    "axs[4].legend(hands, labs, bbox_to_anchor=(-.2, .2, 1.3, 1.), loc=\"lower left\", mode='expand')\n",
    "axs[4].axis('off')\n",
    "\n",
    "_ = gpl.enumerate_subplots(axs[:4], pos_x=0.01, pos_y=1.05, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check consistency with duration of window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 10\n",
    "window_arr = [20, 30, 40]\n",
    "nrows = len(window_arr) \n",
    "class_names = ['Extreme El Nino', 'EP El Nino', 'CP El Nino', 'EP La Nina', 'CP La Nina', 'cov']\n",
    "\n",
    "fig, axs = plt.subplots(nrows, 1, figsize=(7, nrows*1.5), sharex=True)\n",
    "\n",
    "\n",
    "for i, n_years in enumerate(window_arr):\n",
    "    nino34_var, times = rolling_window_covariance(nino34, window_size=3*n_years)\n",
    "    nino34_var = xr.DataArray(nino34_var, coords=dict(time=times))\n",
    "    nino34_k_cov, times = rolling_window_covariance(nino34_k, window_size=3*n_years)\n",
    "    nino34_k_cov = xr.DataArray(nino34_k_cov, coords=dict(time=times, c1=nino34_k['classes'].data, c2=nino34_k['classes'].data))\n",
    "    \n",
    "    # Sum of covariances\n",
    "    n_times, n_features, _ = nino34_k_cov.shape\n",
    "    sum_covariances = np.zeros(n_times)\n",
    "    for j in range(n_features):\n",
    "        for k in range(j+1, n_features):\n",
    "            sum_covariances += nino34_k_cov.data[:, j, k]\n",
    "    nino34_k_cov_sum = xr.DataArray(2*sum_covariances, coords=dict(time=nino34_k_cov['time'].data))\n",
    "    \n",
    "    year_arr = np.arange(np.array(nino34_k_cov['time'].min().data, dtype='datetime64[Y]'),\n",
    "                         np.array(nino34_k_cov['time'].max().data, dtype='datetime64[Y]') + np.timedelta64(2, 'Y'),\n",
    "                         step=n_step, dtype='datetime64[Y]')\n",
    "    time_arr = np.array([f\"{y}-01-01\" for y in year_arr], dtype='datetime64[D]')\n",
    "    # Select time points and stack plots\n",
    "    stacked_lines = [(nino34_k_cov.sel(time=time_arr, method='nearest').isel(c1=k, c2=k) / nino34_var\n",
    "                      ) for k in gmm_order]\n",
    "    stacked_lines.append(\n",
    "        nino34_k_cov_sum.sel(time=time_arr, method='nearest') / nino34_var\n",
    "    )\n",
    "\n",
    "    # Decadel variability\n",
    "    bottom = np.zeros_like(stacked_lines[0])\n",
    "    for j, stack in enumerate(stacked_lines):\n",
    "        if i == 0:\n",
    "            axs[i].bar(time_arr, stack, bottom=bottom, width=3.5e3, color=clrs[j], label=class_names[j])\n",
    "        else:\n",
    "            axs[i].bar(time_arr, stack, bottom=bottom, width=3.5e3, color=clrs[j])\n",
    "        bottom += stack\n",
    "    axs[i].set_ylabel(r\"$\\overline{\\sigma}$ \" + f\"(w={n_years}y)\")\n",
    "\n",
    "fig.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.1, 1.0, .85, 0.1), mode='expand')\n",
    "gpl.enumerate_subplots(axs, pos_x=0.01, pos_y=.85, fontsize=12)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('vaeenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd1f84a93514db3fb3689a6c2d4c248cfb632ba5f8c260d8b9cf936021326503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
